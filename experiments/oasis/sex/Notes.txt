Scratch, direct transfer, elastic: done 

Ft-final sex: Optimizing hyperparameters.

Sex-pretrained: done - kind of! In fact, we still optimize hyperparameters!
- however, it is very weird that the results are only slighlty better than
the ones not trained at all. We still run experiments where we re-run with a very small learning rate to see how that goes. We still
try to optimize hyperparameters to make it work better!

We should also think re-training only the final layer to see how that goes. It seems that there might not be a big advantage actually!
Compare with age!

- THINK ABOUT HAVING AN OPTIMAL PROCEDURE WHICH GOES 
MODEL.EVAL() + ONLY TRAINING FINAL LAYER (I.E.ALLOW THE MODEL TO BE TRAINED WITHOUT UPDATING BATCHNORM)

- WE CHANGED THE CODE SUCH THAT THE FINAL LAYER IS NOT REINITIALIZED WHEN IT HAS THE SAME SHAPE.
WE TESTED IT WITH ft_final/exp_2_* and --/exp_2_*



