------------------------------------------------
Job ID: 42126836
Run on host: compg013.hpc.in.bmrc.ox.ac.uk
Operating system: Linux
Username: lhw539
Started at: Sun Mar 28 21:51:08 BST 2021
------------------------------------------------
Test (in contrast to train):  False
Loading ABIDE train data.
The data was balanced for  sex .
Loading ABIDE   val data.
The data was balanced for  sex .
Load model for sex - run: 0
Output dimensions match.
Number of GPUs:  2
Epoch decay:  20
Gamma decay:  0.5

Full model is being trained with weights loaded from pre-trained model.
Start:  2021-03-28 21:51:15.802211
----------------------------------------------------------------------------------------------------------------------------------------------------------------
|epoch:   0 | lr: 0.005 |train ent: 0.87511 |train ent ravg: 0.87511 |train acc:  0.52706 |train acc ravg:  0.52706 |val ent: 0.74740 |val entravg: 0.74740 |val acc:  0.47959 |val acc ravg:  0.47959 |
|epoch:   1 | lr: 0.005 |train ent: 0.74074 |train ent ravg: 0.80792 |train acc:  0.52191 |train acc ravg:  0.52448 |val ent: 0.74125 |val entravg: 0.74433 |val acc:  0.50000 |val acc ravg:  0.48980 |
|epoch:   2 | lr: 0.005 |train ent: 0.71302 |train ent ravg: 0.77629 |train acc:  0.52448 |train acc ravg:  0.52448 |val ent: 0.71991 |val entravg: 0.73619 |val acc:  0.50000 |val acc ravg:  0.49320 |
|epoch:   3 | lr: 0.005 |train ent: 0.69566 |train ent ravg: 0.75613 |train acc:  0.55155 |train acc ravg:  0.53125 |val ent: 0.71845 |val entravg: 0.73175 |val acc:  0.48724 |val acc ravg:  0.49171 |
|epoch:   4 | lr: 0.005 |train ent: 0.68556 |train ent ravg: 0.74202 |train acc:  0.56830 |train acc ravg:  0.53866 |val ent: 0.69871 |val entravg: 0.72514 |val acc:  0.53827 |val acc ravg:  0.50102 |
|epoch:   5 | lr: 0.005 |train ent: 0.69701 |train ent ravg: 0.70640 |train acc:  0.55155 |train acc ravg:  0.54356 |val ent: 0.76078 |val entravg: 0.72782 |val acc:  0.51020 |val acc ravg:  0.50714 |
|epoch:   6 | lr: 0.005 |train ent: 0.67820 |train ent ravg: 0.69389 |train acc:  0.58763 |train acc ravg:  0.55670 |val ent: 0.84454 |val entravg: 0.74848 |val acc:  0.54592 |val acc ravg:  0.51633 |
|epoch:   7 | lr: 0.005 |train ent: 0.68684 |train ent ravg: 0.68865 |train acc:  0.56186 |train acc ravg:  0.56418 |val ent: 0.70211 |val entravg: 0.74492 |val acc:  0.56633 |val acc ravg:  0.52959 |
|epoch:   8 | lr: 0.005 |train ent: 0.67820 |train ent ravg: 0.68516 |train acc:  0.59665 |train acc ravg:  0.57320 |val ent: 0.72698 |val entravg: 0.74662 |val acc:  0.56378 |val acc ravg:  0.54490 |
|epoch:   9 | lr: 0.005 |train ent: 0.66041 |train ent ravg: 0.68013 |train acc:  0.61469 |train acc ravg:  0.58247 |val ent: 0.71195 |val entravg: 0.74927 |val acc:  0.55867 |val acc ravg:  0.54898 |
|epoch:  10 | lr: 0.005 |train ent: 0.65834 |train ent ravg: 0.67240 |train acc:  0.63402 |train acc ravg:  0.59897 |val ent: 0.80910 |val entravg: 0.75893 |val acc:  0.47959 |val acc ravg:  0.54286 |
|epoch:  11 | lr: 0.005 |train ent: 0.65927 |train ent ravg: 0.66861 |train acc:  0.62629 |train acc ravg:  0.60670 |val ent: 0.68365 |val entravg: 0.72676 |val acc:  0.58673 |val acc ravg:  0.55102 |
|epoch:  12 | lr: 0.005 |train ent: 0.65204 |train ent ravg: 0.66165 |train acc:  0.62758 |train acc ravg:  0.61985 |val ent: 1.24823 |val entravg: 0.83598 |val acc:  0.50255 |val acc ravg:  0.53827 |
|epoch:  13 | lr: 0.005 |train ent: 0.64328 |train ent ravg: 0.65467 |train acc:  0.63918 |train acc ravg:  0.62835 |val ent: 0.71040 |val entravg: 0.83266 |val acc:  0.51276 |val acc ravg:  0.52806 |
|epoch:  14 | lr: 0.005 |train ent: 0.63770 |train ent ravg: 0.65013 |train acc:  0.63660 |train acc ravg:  0.63273 |val ent: 0.73009 |val entravg: 0.83629 |val acc:  0.48724 |val acc ravg:  0.51378 |
|epoch:  15 | lr: 0.005 |train ent: 0.64832 |train ent ravg: 0.64812 |train acc:  0.63660 |train acc ravg:  0.63325 |val ent: 0.72026 |val entravg: 0.81853 |val acc:  0.55357 |val acc ravg:  0.52857 |
|epoch:  16 | lr: 0.005 |train ent: 0.63566 |train ent ravg: 0.64340 |train acc:  0.64304 |train acc ravg:  0.63660 |val ent: 0.68640 |val entravg: 0.81908 |val acc:  0.57143 |val acc ravg:  0.52551 |
|epoch:  17 | lr: 0.005 |train ent: 0.62782 |train ent ravg: 0.63856 |train acc:  0.63789 |train acc ravg:  0.63866 |val ent: 0.72334 |val entravg: 0.71410 |val acc:  0.50000 |val acc ravg:  0.52500 |
|epoch:  18 | lr: 0.005 |train ent: 0.62100 |train ent ravg: 0.63410 |train acc:  0.66495 |train acc ravg:  0.64381 |val ent: 0.76075 |val entravg: 0.72417 |val acc:  0.52296 |val acc ravg:  0.52704 |
|epoch:  19 | lr: 0.005 |train ent: 0.60419 |train ent ravg: 0.62740 |train acc:  0.68299 |train acc ravg:  0.65309 |val ent: 0.67417 |val entravg: 0.71298 |val acc:  0.56122 |val acc ravg:  0.54184 |
|epoch:  20 | lr: 0.003 |train ent: 0.57089 |train ent ravg: 0.61191 |train acc:  0.69588 |train acc ravg:  0.66495 |val ent: 0.67588 |val entravg: 0.70411 |val acc:  0.63010 |val acc ravg:  0.55714 |
|epoch:  21 | lr: 0.003 |train ent: 0.54127 |train ent ravg: 0.59303 |train acc:  0.72036 |train acc ravg:  0.68041 |val ent: 0.67268 |val entravg: 0.70136 |val acc:  0.67602 |val acc ravg:  0.57806 |
|epoch:  22 | lr: 0.003 |train ent: 0.53222 |train ent ravg: 0.57391 |train acc:  0.74613 |train acc ravg:  0.70206 |val ent: 0.70798 |val entravg: 0.69829 |val acc:  0.59439 |val acc ravg:  0.59694 |
|epoch:  23 | lr: 0.003 |train ent: 0.53991 |train ent ravg: 0.55770 |train acc:  0.72680 |train acc ravg:  0.71443 |val ent: 0.67428 |val entravg: 0.68100 |val acc:  0.63776 |val acc ravg:  0.61990 |
|epoch:  24 | lr: 0.003 |train ent: 0.53397 |train ent ravg: 0.54365 |train acc:  0.73454 |train acc ravg:  0.72474 |val ent: 0.67080 |val entravg: 0.68032 |val acc:  0.61224 |val acc ravg:  0.63010 |
|epoch:  25 | lr: 0.003 |train ent: 0.49321 |train ent ravg: 0.52812 |train acc:  0.76933 |train acc ravg:  0.73943 |val ent: 3.75747 |val entravg: 1.29664 |val acc:  0.50510 |val acc ravg:  0.60510 |
|epoch:  26 | lr: 0.003 |train ent: 0.47932 |train ent ravg: 0.51573 |train acc:  0.78222 |train acc ravg:  0.75180 |val ent: 0.88243 |val entravg: 1.33859 |val acc:  0.55102 |val acc ravg:  0.58010 |
|epoch:  27 | lr: 0.003 |train ent: 0.48302 |train ent ravg: 0.50589 |train acc:  0.78995 |train acc ravg:  0.76057 |val ent: 0.69654 |val entravg: 1.33630 |val acc:  0.59694 |val acc ravg:  0.58061 |
|epoch:  28 | lr: 0.003 |train ent: 0.45827 |train ent ravg: 0.48956 |train acc:  0.77964 |train acc ravg:  0.77113 |val ent: 1.03996 |val entravg: 1.40944 |val acc:  0.54592 |val acc ravg:  0.56224 |
|epoch:  29 | lr: 0.003 |train ent: 0.45528 |train ent ravg: 0.47382 |train acc:  0.79253 |train acc ravg:  0.78273 |val ent: 0.65690 |val entravg: 1.40666 |val acc:  0.61224 |val acc ravg:  0.56224 |
|epoch:  30 | lr: 0.003 |train ent: 0.43297 |train ent ravg: 0.46177 |train acc:  0.80799 |train acc ravg:  0.79046 |val ent: 0.66661 |val entravg: 0.78849 |val acc:  0.59949 |val acc ravg:  0.58112 |
|epoch:  31 | lr: 0.003 |train ent: 0.42133 |train ent ravg: 0.45017 |train acc:  0.81572 |train acc ravg:  0.79716 |val ent: 1.18863 |val entravg: 0.84973 |val acc:  0.49745 |val acc ravg:  0.57041 |
|epoch:  32 | lr: 0.003 |train ent: 0.42274 |train ent ravg: 0.43812 |train acc:  0.81959 |train acc ravg:  0.80309 |val ent: 0.99882 |val entravg: 0.91018 |val acc:  0.56122 |val acc ravg:  0.56327 |
|epoch:  33 | lr: 0.003 |train ent: 0.38931 |train ent ravg: 0.42433 |train acc:  0.84407 |train acc ravg:  0.81598 |val ent: 1.10966 |val entravg: 0.92412 |val acc:  0.59949 |val acc ravg:  0.57398 |
|epoch:  34 | lr: 0.003 |train ent: 0.41629 |train ent ravg: 0.41653 |train acc:  0.83119 |train acc ravg:  0.82371 |val ent: 2.46570 |val entravg: 1.28588 |val acc:  0.51276 |val acc ravg:  0.55408 |
|epoch:  35 | lr: 0.003 |train ent: 0.36523 |train ent ravg: 0.40298 |train acc:  0.84794 |train acc ravg:  0.83170 |val ent: 0.68085 |val entravg: 1.28873 |val acc:  0.60204 |val acc ravg:  0.55459 |
|epoch:  36 | lr: 0.003 |train ent: 0.36398 |train ent ravg: 0.39151 |train acc:  0.84278 |train acc ravg:  0.83711 |val ent: 0.65767 |val entravg: 1.18254 |val acc:  0.63010 |val acc ravg:  0.58112 |
|epoch:  37 | lr: 0.003 |train ent: 0.35618 |train ent ravg: 0.37820 |train acc:  0.85438 |train acc ravg:  0.84407 |val ent: 1.16594 |val entravg: 1.21596 |val acc:  0.52806 |val acc ravg:  0.57449 |
|epoch:  38 | lr: 0.003 |train ent: 0.26751 |train ent ravg: 0.35384 |train acc:  0.90979 |train acc ravg:  0.85722 |val ent: 0.56794 |val entravg: 1.10762 |val acc:  0.74490 |val acc ravg:  0.60357 |
|epoch:  39 | lr: 0.003 |train ent: 0.31392 |train ent ravg: 0.33336 |train acc:  0.87113 |train acc ravg:  0.86521 |val ent: 2.02814 |val entravg: 1.02010 |val acc:  0.51020 |val acc ravg:  0.60306 |
|epoch:  40 | lr: 0.001 |train ent: 0.27553 |train ent ravg: 0.31542 |train acc:  0.90851 |train acc ravg:  0.87732 |val ent: 0.54203 |val entravg: 0.99234 |val acc:  0.75000 |val acc ravg:  0.63265 |
|epoch:  41 | lr: 0.001 |train ent: 0.21838 |train ent ravg: 0.28630 |train acc:  0.93686 |train acc ravg:  0.89613 |val ent: 0.55338 |val entravg: 0.97149 |val acc:  0.76276 |val acc ravg:  0.65918 |
|epoch:  42 | lr: 0.001 |train ent: 0.17275 |train ent ravg: 0.24962 |train acc:  0.95876 |train acc ravg:  0.91701 |val ent: 0.56291 |val entravg: 0.85088 |val acc:  0.72959 |val acc ravg:  0.69949 |
|epoch:  43 | lr: 0.001 |train ent: 0.19061 |train ent ravg: 0.23424 |train acc:  0.95103 |train acc ravg:  0.92526 |val ent: 0.62529 |val entravg: 0.86235 |val acc:  0.66582 |val acc ravg:  0.68367 |
|epoch:  44 | lr: 0.001 |train ent: 0.16977 |train ent ravg: 0.20541 |train acc:  0.95619 |train acc ravg:  0.94227 |val ent: 0.53793 |val entravg: 0.56431 |val acc:  0.74490 |val acc ravg:  0.73061 |
|epoch:  45 | lr: 0.001 |train ent: 0.16859 |train ent ravg: 0.18402 |train acc:  0.95232 |train acc ravg:  0.95103 |val ent: 1.39240 |val entravg: 0.73438 |val acc:  0.53061 |val acc ravg:  0.68673 |
|epoch:  46 | lr: 0.001 |train ent: 0.16984 |train ent ravg: 0.17431 |train acc:  0.95876 |train acc ravg:  0.95541 |val ent: 0.68977 |val entravg: 0.76166 |val acc:  0.66837 |val acc ravg:  0.66786 |
|epoch:  47 | lr: 0.001 |train ent: 0.13994 |train ent ravg: 0.16775 |train acc:  0.96907 |train acc ravg:  0.95747 |val ent: 0.54902 |val entravg: 0.75888 |val acc:  0.76020 |val acc ravg:  0.67398 |
|epoch:  48 | lr: 0.001 |train ent: 0.13133 |train ent ravg: 0.15590 |train acc:  0.97552 |train acc ravg:  0.96237 |val ent: 0.62335 |val entravg: 0.75849 |val acc:  0.76531 |val acc ravg:  0.69388 |
|epoch:  49 | lr: 0.001 |train ent: 0.13942 |train ent ravg: 0.14983 |train acc:  0.96778 |train acc ravg:  0.96469 |val ent: 0.60045 |val entravg: 0.77100 |val acc:  0.74490 |val acc ravg:  0.69388 |
|epoch:  50 | lr: 0.001 |train ent: 0.14731 |train ent ravg: 0.14557 |train acc:  0.96649 |train acc ravg:  0.96753 |val ent: 0.80125 |val entravg: 0.65277 |val acc:  0.65561 |val acc ravg:  0.71888 |
|epoch:  51 | lr: 0.001 |train ent: 0.13819 |train ent ravg: 0.13924 |train acc:  0.96392 |train acc ravg:  0.96856 |val ent: 0.60197 |val entravg: 0.63521 |val acc:  0.72959 |val acc ravg:  0.73112 |
|epoch:  52 | lr: 0.001 |train ent: 0.13717 |train ent ravg: 0.13868 |train acc:  0.96778 |train acc ravg:  0.96830 |val ent: 0.96756 |val entravg: 0.71892 |val acc:  0.62755 |val acc ravg:  0.70459 |
|epoch:  53 | lr: 0.001 |train ent: 0.11270 |train ent ravg: 0.13496 |train acc:  0.98582 |train acc ravg:  0.97036 |val ent: 0.60982 |val entravg: 0.71621 |val acc:  0.71173 |val acc ravg:  0.69388 |
|epoch:  54 | lr: 0.001 |train ent: 0.11240 |train ent ravg: 0.12955 |train acc:  0.98067 |train acc ravg:  0.97294 |val ent: 0.61954 |val entravg: 0.72003 |val acc:  0.72704 |val acc ravg:  0.69031 |
|epoch:  55 | lr: 0.001 |train ent: 0.12386 |train ent ravg: 0.12486 |train acc:  0.97165 |train acc ravg:  0.97397 |val ent: 0.55554 |val entravg: 0.67089 |val acc:  0.74490 |val acc ravg:  0.70816 |
|epoch:  56 | lr: 0.001 |train ent: 0.11212 |train ent ravg: 0.11965 |train acc:  0.97552 |train acc ravg:  0.97629 |val ent: 0.94310 |val entravg: 0.73911 |val acc:  0.60714 |val acc ravg:  0.68367 |
|epoch:  57 | lr: 0.001 |train ent: 0.09971 |train ent ravg: 0.11216 |train acc:  0.98325 |train acc ravg:  0.97938 |val ent: 0.70049 |val entravg: 0.68570 |val acc:  0.67347 |val acc ravg:  0.69286 |
|epoch:  58 | lr: 0.001 |train ent: 0.10614 |train ent ravg: 0.11084 |train acc:  0.97423 |train acc ravg:  0.97706 |val ent: 0.59151 |val entravg: 0.68204 |val acc:  0.68112 |val acc ravg:  0.68673 |
|epoch:  59 | lr: 0.001 |train ent: 0.08475 |train ent ravg: 0.10531 |train acc:  0.98454 |train acc ravg:  0.97784 |val ent: 0.59162 |val entravg: 0.67646 |val acc:  0.75510 |val acc ravg:  0.69235 |
----------------------------------------------------------------------------------------------------------------------------------------------------------------
Finished:  2021-03-29 03:04:45.307728

Correlation between train loss and evaluation: -0.986

----------------------------------------------------------------------------------------------------------------------------------------------------------------
Save configfile.
Loading ABIDE  test data.
The data was balanced for  sex .
Number of GPUs:  2

Model loaded from None is being tested.
Start:  2021-03-29 03:04:45.405239
----------------------------------------------------------------------------------------------------------------------------------------------------------------
test ent mean: 0.55432 | test ent std: 0.00069 |test acc mean:  0.74387 |test acc std:  0.00000 |
----------------------------------------------------------------------------------------------------------------------------------------------------------------
Finished:  2021-03-29 03:07:19.766027

Correlation between train loss and evaluation: -0.000

----------------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------
Finished at: Mon Mar 29 03:07:20 BST 2021
------------------------------------------------
------------------------------------------------
Job ID: 43538414
Run on host: compg009.hpc.in.bmrc.ox.ac.uk
Operating system: Linux
Username: lhw539
Started at: Sun Apr 11 17:57:38 BST 2021
------------------------------------------------
Test (in contrast to train):  False
Loading ABIDE train data.
The data was balanced for  sex .
Loading ABIDE   val data.
The data was balanced for  sex .
Load model for sex - run: 0
Output dimensions match.
Number of GPUs:  2
Epoch decay:  20
Gamma decay:  0.5

Full model is being trained with weights loaded from pre-trained model.
Start:  2021-04-11 17:57:46.204726
----------------------------------------------------------------------------------------------------------------------------------------------------------------
Traceback (most recent call last):
  File "/users/win-fmrib-analysis/lhw539/TransferLearning_Neuroimaging/main.py", line 130, in <module>
    model=train_full_sfcn_preloaded(train_loader,val_loader,hps)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/TransferLearning_Neuroimaging/methods/ft_full.py", line 54, in train_full_sfcn_preloaded
    info_end=info_end)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/TransferLearning_Neuroimaging/sfcn/sfcn_train.py", line 50, in sfcn_train
    info_end=info_end)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/TransferLearning_Neuroimaging/train_and_test/training.py", line 98, in run_training
    scheduler=scheduler)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/TransferLearning_Neuroimaging/train_and_test/training.py", line 23, in train
    eval_func=eval_func)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/TransferLearning_Neuroimaging/train_and_test/epoch.py", line 45, in go_one_epoch
    output = model(data)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/python/tlneuro-skylake/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/python/tlneuro-skylake/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 161, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/python/tlneuro-skylake/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 171, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/gpfs3/users/win-fmrib-analysis/lhw539/python/tlneuro-skylake/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/gpfs3/users/win-fmrib-analysis/lhw539/python/tlneuro-skylake/lib/python3.7/site-packages/torch/_utils.py", line 428, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/gpfs3/users/win-fmrib-analysis/lhw539/python/tlneuro-skylake/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/python/tlneuro-skylake/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/TransferLearning_Neuroimaging/sfcn/sfcn_model.py", line 96, in forward
    x_f = self.feature_extractor(x)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/python/tlneuro-skylake/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/python/tlneuro-skylake/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/python/tlneuro-skylake/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/python/tlneuro-skylake/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/python/tlneuro-skylake/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/python/tlneuro-skylake/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 136, in forward
    self.weight, self.bias, bn_training, exponential_average_factor, self.eps)
  File "/gpfs3/users/win-fmrib-analysis/lhw539/python/tlneuro-skylake/lib/python3.7/site-packages/torch/nn/functional.py", line 2058, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 544.00 MiB (GPU 0; 15.90 GiB total capacity; 5.82 GiB already allocated; 380.75 MiB free; 5.83 GiB reserved in total by PyTorch)

------------------------------------------------
Finished at: Sun Apr 11 17:57:55 BST 2021
------------------------------------------------
